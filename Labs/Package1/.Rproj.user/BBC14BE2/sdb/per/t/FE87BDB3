{
    "contents" : "require(ggplot2)\nrequire(plyr)\nrequire(grid)\n\nsetwd(\"/Users/michaelpiccirilli/Desktop/UNDP-BCPR-Project/interval_csv\")\nall <- read.csv(file=\"june11_may13.csv\", header=T,sep=\",\")\n\n\n#look at only Georgian events #\ngeo.subset <- subset(all, Actor1CountryCode==\"GEO\" & Actor2CountryCode==\"GEO\")\n\ngeo.subset$ActionGeo_FullName <- gsub(\"Georgia \\\\(general\\\\)\\\\,[[:blank:]]\",\"\",geo.subset$ActionGeo_FullName, ignore.case=T)\ngeo.subset$ActionGeo_FullName <- gsub(\"[[:alpha:]]+[[:punct:]]{3}[[:blank:]]\",\"\",geo.subset$ActionGeo_FullName, ignore.case=T)\n\n\ngeo.name.1 <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                      EventBaseCode + ActionGeo_FullName + Actor1Name,\n                    geo.subset,sum)\n\n\ngeo.name.2 <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                      EventBaseCode + ActionGeo_FullName + Actor2Name,\n                    geo.subset,sum)\n\ngeo.merge.names <- merge(geo.name.1,geo.name.2, by = \"GLOBALEVENTID\")\ncolnames(geo.merge.names)\ngeo.merge.names <- geo.merge.names[,c(1:6,10)]\ncolnames(geo.merge.names)[1:7] <- c(\"GLOBALEVENTID\", \"SQLDATE\", \"EventBaseCode\", \"ActionGeo_FullName\",\"Actor1Name\", \"NumArticles\", \"Actor2Name\")\n\n\n\ngeo.country <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                       EventBaseCode + ActionGeo_FullName + \n                       Actor1CountryCode + Actor2CountryCode,\n                     geo.subset,sum)\n\ngeo.merge.name.country <- merge(geo.country, geo.merge.names, by= \"GLOBALEVENTID\")\ncolnames(geo.merge.name.country)\ngeo.merge.name.country <- geo.merge.name.country[,c(1:7,11,13)]\ncolnames(geo.merge.name.country)[2:4] <- c(\"SQLDATE\", \"EventBaseCode\",\"ActionGeo_FullName\")\ncolnames(merge.name.country)[7] <- \"NumArticles\"\n\nrm(geo.country,geo.name.1,geo.name.2,geo.merge.names)\n\ngeo.goldstein.tone <- aggregate(NumArticles ~ GLOBALEVENTID +\n                              EventCode + GoldsteinScale +\n                              AvgTone,\n                            geo.subset,sum)\n\ngeo.merge.complete <- merge(geo.merge.name.country,geo.goldstein.tone, by=\"GLOBALEVENTID\")\ncolnames(geo.merge.complete)\ngeo.merge.complete <- geo.merge.complete[,c(1,2,3,10,7,5,8,6,9,4,11,12)]\ncolnames(merge.complete)[5] <- \"NumArticles\"\n\n\ngeo.actor.freq <- count(geo.merge.complete,c(\"Actor1Name\",\"Actor2Name\",\"GoldsteinScale\",\"AvgTone\", \"EventBaseCode\"))\ngeo.actor.freq$Freqency.Percent <- (geo.actor.freq$freq/sum(geo.actor.freq$freq))*100\ncolnames(geo.actor.freq)\ncolnames(geo.actor.freq)[6] <- \"Frequency\"\ngeo.actor.freq <- geo.actor.freq[order(-geo.actor.freq$Frequency),]\nrownames(geo.actor.freq) <- NULL\nsum(geo.actor.freq$Freqency.Percent)\n\nwrite.table(geo.actor.freq,file=\"Georgian-Actor-Frequency-by-Name.csv\",sep=\",\",row.names=F)\n\n\n#create new classifer, multiple goldsteinscale * AvgTone\ngeo.actor.freq$EventMagnitude <- (geo.actor.freq$GoldsteinScale*geo.actor.freq$AvgTone)\n\n#make everything a factor so as to use naiveBayes\nsapply(geo.actor.freq, class)\ngeo.actor.freq$GoldsteinScale <- as.factor(geo.actor.freq$GoldsteinScale)\ngeo.actor.freq$AvgTone <- as.factor(geo.actor.freq$AvgTone)\ngeo.actor.freq$EventBaseCode <- as.factor(geo.actor.freq$EventBaseCode)\ngeo.actor.freq$Frequency <- as.factor(geo.actor.freq$Frequency)\n\n\nsample.geo <- geo.actor.freq[sample(nrow(geo.actor.freq),size=20),]\ncolnames(sample.geo)\nsample.geo <- sample.geo[,c(1,2,3,4,6)]\nrownames(sample.geo) <- NULL\n\nEventCode <- data.frame(sample.geo$EventBaseCode)\n\nnb.geo <- naiveBayes(EventBaseCode ~., geo.actor.freq)\nhead(nb.geo$tables)\n\npredict.geo <- predict(nb.geo, sample.geo)\npredict.geo <- data.frame(predict.geo)\npredict.geo$actual <- EventCode$sample.geo.EventBaseCode\n\n\n\n\n\n#Look at data w/out USA info -- it's littered with events re: Georgia, US\nall.subset <- subset(all, Actor1CountryCode!=\"USA\" & Actor2CountryCode!=\"USA\")\nrownames(all.subset) <- NULL\ncolnames(all.subset)\n\nall.subset$ActionGeo_FullName <- gsub(\"Georgia \\\\(general\\\\)\\\\,[[:blank:]]\",\"\",all.subset$ActionGeo_FullName, ignore.case=T)\nall.subset$ActionGeo_FullName <- gsub(\"[[:alpha:]]+[[:punct:]]{3}[[:blank:]]\",\"\",all.subset$ActionGeo_FullName, ignore.case=T)\n\n\n#I don't understand why, but I can't create a dataframe by \n# aggregating both the ActorCountryCodes and ActorNames. I also can't include\n# the GoldsteinScale and/or AvgTone.  However I can create the \n# DFs separately, then merge them together based on the GlobalEventID\n\nsapply(all.subset,class)\n\n\nname.1 <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                                  EventBaseCode + ActionGeo_FullName + Actor1Name,\n                                all.subset,sum)\n\n\nname.2 <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                                  EventBaseCode + ActionGeo_FullName + Actor2Name,\n                                all.subset,sum)\n\nmerge.names <- merge(name.1,name.2, by = \"GLOBALEVENTID\")\ncolnames(merge.names)\nmerge.names <- merge.names[,c(1:6,10)]\ncolnames(merge.names)[1:7] <- c(\"GLOBALEVENTID\", \"SQLDATE\", \"EventBaseCode\", \"ActionGeo_FullName\",\"Actor1Name\", \"NumArticles\", \"Actor2Name\")\n\n\n\ncountry <- aggregate(NumArticles ~ GLOBALEVENTID + SQLDATE +\n                                     EventBaseCode + ActionGeo_FullName + \n                                     Actor1CountryCode + Actor2CountryCode,\n                                   all.subset,sum)\n\nmerge.name.country <- merge(country, merge.names, by= \"GLOBALEVENTID\")\ncolnames(merge.name.country)\nmerge.name.country <- merge.name.country[,c(1:7,11,13)]\ncolnames(merge.name.country)[2:4] <- c(\"SQLDATE\", \"EventBaseCode\",\"ActionGeo_FullName\")\ncolnames(merge.name.country)[7] <- \"NumArticles\"\n\nrm(country,name.1,name.2,merge.names)\n\ngoldstein.tone <- aggregate(NumArticles ~ GLOBALEVENTID +\n                                EventCode + GoldsteinScale +\n                                AvgTone,\n                              all.subset,sum)\n\nmerge.complete <- merge(merge.name.country,goldstein.tone, by=\"GLOBALEVENTID\")\ncolnames(merge.complete)\nmerge.complete <- merge.complete[,c(1,2,3,10,7,5,8,6,9,4,11,12)]\ncolnames(merge.complete)[5] <- \"NumArticles\"\n\nsetwd(\"/Users/michaelpiccirilli/Desktop\")\nwrite.table(merge.complete,file=\"totalmerge.csv\",sep=\",\",row.names=F)\n\n\n\n\n### Create the DFs for the \nactor1.frequency.list <- subset(data.frame(table(merge.complete$Actor1Name)),Freq!=0)\nactor1.frequency.list$Percent <- (actor1.frequency.list$Freq/sum(actor1.frequency.list$Freq))*100\nrownames(actor1.frequency.list) <- NULL\ncolnames(actor1.frequency.list)[1:2] <- c(\"Actor1Name\",\"Frequency\")\nsum(actor1.frequency.list$Percent)\n\n\nactor2.frequency.list <- subset(data.frame(table(merge.complete$Actor2Name)),Freq!=0)\nactor2.frequency.list$Percent <- (actor2.frequency.list$Freq/sum(actor2.frequency.list$Freq))*100\nrownames(actor2.frequency.list) <- NULL\ncolnames(actor2.frequency.list)[1:2] <- c(\"Actor2Name\",\"Frequency\")\nsum(actor2.frequency.list$Percent)\n\nwrite.table(actor1.frequency.list,file=\"actor1freq.csv\",sep=\",\",row.names=F)\nwrite.table(actor2.frequency.list,file=\"actor2freq.csv\",sep=\",\",row.names=F)\n\n\n\n#Frequency by CountryCode with event codes\nactor.freq.code <- count(merge.complete,c(\"Actor1CountryCode\",\"Actor2CountryCode\",\"EventBaseCode\", \"GoldsteinScale\",\"AvgTone\"))\nactor.freq.code$Freqency.Percent <- (actor.freq.code$freq/sum(actor.freq.code$freq))*100\ncolnames(actor.freq.code)\ncolnames(actor.freq.code)[6] <- \"Frequency\"\nactor.freq.code <- actor.freq.code[order(-actor.freq.code$Frequency),]\nrownames(actor.freq.code) <- NULL\n\n#I wonder what \n\n\n\n\n\n#Frequency by CountryCode WITHOUT event codes\nactor.freq <- count(merge.complete,c(\"Actor1CountryCode\",\"Actor2CountryCode\"))\nactor.freq$Freqency.Percent <- (actor.freq$freq/sum(actor.freq$freq))*100\ncolnames(actor.freq)\ncolnames(actor.freq)[3] <- \"Frequency\"\nactor.freq <- actor.freq[order(-actor.freq$Frequency),]\nrownames(actor.freq) <- NULL\n\nwrite.table(actor.freq,file=\"actor-frequency-by-ISO.csv\",sep=\",\",row.names=F)\n\n\n\n\n#Frequency by ActorName\nactor.freq.name <- count(merge.complete,c(\"Actor1Name\",\"Actor2Name\",\"EventCode\",\"EventBaseCode\"))\nactor.freq.name$Freqency.Percent <- (actor.freq.name$freq/sum(actor.freq.name$freq))*100\ncolnames(actor.freq.name)\ncolnames(actor.freq.name)[5] <- \"Frequency\"\nactor.freq.name <- actor.freq.name[order(-actor.freq.name$Frequency),]\nrownames(actor.freq.name) <- NULL\n\n\nwrite.table(actor.freq.name,file=\"actor1name-actor2name.csv\",sep=\",\",row.names=F)\n\n\n#Frequency by ActorName\nactor.freq.name.ex <- count(merge.complete,c(\"Actor1Name\",\"Actor2Name\"))\nactor.freq.name.ex$Freqency.Percent <- (actor.freq.name.ex$freq/sum(actor.freq.name.ex$freq))*100\ncolnames(actor.freq.name.ex)\ncolnames(actor.freq.name.ex)[3] <- \"Frequency\"\nactor.freq.name.ex <- actor.freq.name.ex[order(-actor.freq.name.ex$Frequency),]\nrownames(actor.freq.name.ex) <- NULL\nsum(actor.freq.name.ex$Freqency.Percent)\n\n\n\n## This is a more complete table of the \n## frequency of both Actor1 and Actor2 together, order to make predictions \n\nactor.freq <- count(merge.complete,c(\"Actor1Name\",\"Actor2Name\",\"Actor1CountryCode\",\"Actor2CountryCode\",\"EventCode\",\"EventBaseCode\",\"ActionGeo_FullName\",\"GoldsteinScale\",\"AvgTone\"))\nactor.freq$Freqency.Percent <- (actor.freq$freq/sum(actor.freq$freq))*100\ncolnames(actor.freq)\ncolnames(actor.freq)[10] <- \"Frequency\"\nactor.freq <- actor.freq[,c(10,11,3,1,4,2,7,5,6,8,9)]\nactor.freq <- actor.freq[order(-actor.freq$Frequency),]\nrownames(actor.freq) <- NULL\n\n\nwrite.table(actor.freq,file=\"actor1-actor2.csv\",sep=\",\",row.names=F)\n",
    "created" : 1386118384499.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "236889005",
    "id" : "FE87BDB3",
    "lastKnownWriteTime" : 1386112666,
    "path" : "~/Desktop/GDELT-UPDATE.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}